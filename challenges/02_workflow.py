# /// script
# requires-python = ">=3.10"
# dependencies = [
#     "openai",
# ]
# ///

import os
import json
import sys
import time
from openai import OpenAI

# ==========================================
# é…ç½®åŒºåŸŸ
# ==========================================
API_KEY = os.getenv("DEEPSEEK_API_KEY")
BASE_URL = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
# å…è®¸ä»ç¯å¢ƒå˜é‡è¦†ç›–æ¨¡å‹åç§°ï¼Œé»˜è®¤ä¸º deepseek-chat
MODEL_NAME = os.getenv("DEEPSEEK_MODEL_NAME", "deepseek-chat")

if not API_KEY:
    print("âŒ Error: è¯·è®¾ç½®ç¯å¢ƒå˜é‡ DEEPSEEK_API_KEY")
    sys.exit(1)

client = OpenAI(api_key=API_KEY, base_url=BASE_URL)

class LongArticleAgent:
    def __init__(self, topic):
        self.topic = topic
        self.outline = []
        self.articles = []

    def step1_generate_outline(self):
        """Step 1: ç”Ÿæˆç« èŠ‚å¤§çº²"""
        print(f"ğŸ“‹ æ­£åœ¨è§„åˆ’ä¸»é¢˜: {self.topic}...")
        
        # TODO: ç¼–å†™ Prompt è®©æ¨¡å‹ç”Ÿæˆçº¯ JSON åˆ—è¡¨
        prompt = prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªå†…å®¹ç»“æ„åŒ–ç”Ÿæˆæ¨¡å‹ï¼Œåªå…è®¸è¾“å‡ºåˆæ³• JSONã€‚

        è¯·ä¸ºä¸»é¢˜ã€Š{self.topic}ã€‹ç”Ÿæˆä¸€ä¸ª JSON æ•°ç»„ï¼ˆArrayï¼‰ï¼Œæ•°ç»„åŒ…å« 3 ä¸ªå¯¹è±¡ï¼Œæ¯ä¸ªå¯¹è±¡å¯¹åº”ä¸€ä¸ªç« èŠ‚ã€‚

        ä¸¥æ ¼è¦æ±‚ï¼š
        1. è¾“å‡ºå¿…é¡»æ˜¯ã€çº¯ JSONã€‘ï¼Œç¦æ­¢å‡ºç°ä»»ä½•è§£é‡Šæ€§æ–‡å­—ã€Markdownã€ä»£ç å—æ ‡è®°
        2. é¡¶å±‚ç»“æ„å¿…é¡»æ˜¯ JSON æ•°ç»„
        3. æ•°ç»„é•¿åº¦å¿…é¡»ä¸º 3
        4. æ¯ä¸ªç« èŠ‚å¯¹è±¡å¿…é¡»åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
           - chapter_idï¼šç« èŠ‚åºå·ï¼ˆæ•´æ•°ï¼Œ1~3ï¼‰
           - titleï¼šç« èŠ‚æ ‡é¢˜ï¼ˆå­—ç¬¦ä¸²ï¼‰
           - summaryï¼šç« èŠ‚æ ¸å¿ƒå†…å®¹æ¦‚è¿°ï¼ˆå­—ç¬¦ä¸²ï¼‰
        5. ä¸å¾—å¢åŠ ã€åˆ é™¤æˆ–æ”¹åå­—æ®µ
        6. ä¸å¾—åµŒå¥—é¢å¤–å±‚çº§
        7. è¾“å‡ºè¯­è¨€ä¸ºä¸­æ–‡

        ç°åœ¨å¼€å§‹ç”Ÿæˆã€‚
        """
        
        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†™ä½œè§„åˆ’å¸ˆï¼Œåªè¾“å‡º JSON Arrayã€‚"},
                    {"role": "user", "content": prompt}
                ],
                response_format={"type": "json_object"},
                temperature=0.7
            )
            content = response.choices[0].message.content
            
            # TODO: è§£æè¿”å›çš„ JSON å†…å®¹åˆ° self.outline
            data = json.loads(content)
            
            # ç®€å•çš„å®¹é”™é€»è¾‘ç¤ºä¾‹ï¼ˆå€™é€‰äººéœ€è¦å®Œå–„ï¼‰
            if isinstance(data, list):
                self.outline = data
            elif isinstance(data, dict):
                for key, value in data.items():
                    if isinstance(value, list):
                        self.outline = value
                        break
            
            if not self.outline:
                raise ValueError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„å¤§çº²åˆ—è¡¨")

            print(f"âœ… å¤§çº²å·²ç”Ÿæˆ: {self.outline}")

        except Exception as e:
            print(f"âŒ å¤§çº²ç”Ÿæˆå¤±è´¥: {e}")
            print(f"Raw Content: {content if 'content' in locals() else 'None'}")
            sys.exit(1)

    def step2_generate_content_loop(self):
        """Step 2: å¾ªç¯ç”Ÿæˆå†…å®¹ï¼Œå¹¶ç»´æŠ¤ Context"""
        if not self.outline:
            return

        # åˆå§‹åŒ–ä¸Šä¸‹æ–‡æ‘˜è¦
        previous_summary = "æ–‡ç« å¼€å§‹ã€‚"
        
        print("\nğŸš€ å¼€å§‹æ’°å†™æ­£æ–‡...")
        for i, chapter in enumerate(self.outline):
            print(f"[{i+1}/{len(self.outline)}] æ­£åœ¨æ’°å†™: {chapter}...")
            
            # TODO: æ„é€  Promptï¼Œæ ¸å¿ƒåœ¨äº Context çš„æ³¨å…¥
            prompt = f"""
            ä½ æ˜¯ä¸€åé•¿æ–‡æœ¬å†™ä½œæ¨¡å‹ï¼Œå½“å‰ä»»åŠ¡æ˜¯æ’°å†™æ­£æ–‡å†…å®¹ï¼Œè€Œä¸æ˜¯è§„åˆ’æˆ–æ€»ç»“ã€‚

            ã€å½“å‰ç« èŠ‚ã€‘
            {chapter}

            ã€å‰æƒ…æè¦ï¼ˆå¿…é¡»ä¸¥æ ¼æ‰¿æ¥ï¼Œä¸å¾—å¤è¿°ï¼‰ã€‘
            {previous_summary}

            å†™ä½œè¦æ±‚ï¼ˆå¿…é¡»å…¨éƒ¨éµå®ˆï¼‰ï¼š
            1. ä»…è¾“å‡ºæ­£æ–‡å†…å®¹ï¼Œä¸è¦å‡ºç°æ ‡é¢˜ã€åºå·æˆ–è§£é‡Šæ€§æ–‡å­—
            2. å†…å®¹å¿…é¡»åœ¨é€»è¾‘ä¸Šç›´æ¥æ‰¿æ¥ã€å‰æƒ…æè¦ã€‘ï¼Œè§†å…¶ä¸ºå·²å‘ç”Ÿçš„äº‹å®èƒŒæ™¯
            3. ä¸å¾—é‡å¤ã€å‰æƒ…æè¦ã€‘ä¸­çš„è¡¨è¿°æˆ–ç»“è®º
            4. å¦‚éœ€å¼•å…¥æ–°æ¦‚å¿µï¼Œå¿…é¡»åŸºäºå‰æƒ…è‡ªç„¶å±•å¼€
            5. æ­£æ–‡å­—æ•°æ§åˆ¶åœ¨çº¦ 300 å­—ï¼ˆÂ±50 å­—ï¼‰
            6. è¯­è¨€ä¸ºä¸­æ–‡ï¼Œé£æ ¼å®¢è§‚ã€è¿è´¯ã€åä¹¦é¢

            ç°åœ¨å¼€å§‹æ’°å†™æ­£æ–‡ã€‚
            """
            
            try:
                response = client.chat.completions.create(
                    model=MODEL_NAME,  # ä½¿ç”¨é…ç½®çš„æ¨¡å‹å
                    messages=[{"role": "user", "content": prompt}],
                    temperature=0.7
                )
                content = response.choices[0].message.content
                self.articles.append(f"## {chapter}\n\n{content}")
                
                # TODO: æ›´æ–° Context (æ ¸å¿ƒè€ƒå¯Ÿç‚¹)
                # ç®€å•ç­–ç•¥ï¼šæˆªå–æœ€å 200 å­—
                MAX_CONTEXT_LEN = 200

                previous_summary = content[-MAX_CONTEXT_LEN:] if len(content) > MAX_CONTEXT_LEN else content
                
            except Exception as e:
                print(f"âš ï¸ ç« èŠ‚ {chapter} ç”Ÿæˆå¤±è´¥: {e}")

    def save_result(self):
        if not self.articles:
            print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•å†…å®¹")
            return
            
        filename = "final_article.md"
        with open(filename, "w", encoding="utf-8") as f:
            f.write(f"# {self.topic}\n\n")
            f.write("\n\n".join(self.articles))
        print(f"\nğŸ‰ æ–‡ç« å·²ä¿å­˜è‡³ {filename}")

if __name__ == "__main__":
    print(f"ğŸ”Œ Endpoint: {BASE_URL}")
    print(f"ğŸ§  Model: {MODEL_NAME}\n")
    
    agent = LongArticleAgent("2025å¹´ DeepSeek å¯¹ AI è¡Œä¸šçš„å½±å“")
    agent.step1_generate_outline()
    agent.step2_generate_content_loop()
    agent.save_result()
